{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data, InMemoryDataset\n",
    "import torch_geometric.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "labels = ['addr_contract', 'caller', 'msgvalue', 'balance', 'call_data', 'blk', 'mdata', 'sdata', 'create', 'call', 'callcode', 'delegatecall', 'create2', 'staticcall', 'cal_res', 'comp_res', 'bit_res', 'size', 'code', 'gas', 'return', 'coinbase', 'gasremain', 'revert', 'selfdestruct', 'memory', 'storage', 'flowcontrol']\n",
    "node_types = ['ADDRESS', 'ORIGIN', 'CALLER', 'CALLVALUE', 'BALANCE', 'SELFBALANCE', 'CALLDATALOAD', 'CALLDATACOPY', 'BLOCKHASH', 'TIMESTAMP', 'NUMBER', 'DIFFICULTY', 'BASEFEE', 'MLOAD', 'SLOAD', 'CREATE', 'CALL', 'CALLCODE', 'DELEGATECALL', 'CREATE2', 'STATICCALL', 'ADD', 'MUL', 'SUB', 'EXP', 'LT', 'GT', 'SLT', 'SGT', 'EQ', 'ISZERO', 'AND', 'OR', 'XOR', 'NOT', 'SHL', 'CALLDATASIZE', 'CODESIZE', 'EXTCODESIZE', 'RETURNDATASIZE', 'MSIZE', 'CODECOPY', 'EXTCODECOPY', 'EXTCODEHASH', 'GASPRICE', 'GASLIMIT', 'RETURNDATACOPY', 'RETURN', 'COINBASE', 'GAS', 'REVERT', 'SELFDESTRUCT', 'MSTORE', 'MSTORE8', 'SSTORE', 'JUMP', 'JUMPI', 'JUMPDEST', 'STOP', 'DIV', 'SDIV', 'MOD', 'SMOD', 'ADDMOD', 'SIGNEXTEND', 'BYTE', 'SHR', 'SAR', 'SHA3', 'CHAINID', 'POP', 'PC', 'PUSH1', 'PUSH2', 'PUSH3', 'PUSH4', 'PUSH5', 'PUSH6', 'PUSH7', 'PUSH8', 'PUSH9', 'PUSH10', 'PUSH11', 'PUSH12', 'PUSH13', 'PUSH14', 'PUSH15', 'PUSH16', 'PUSH17', 'PUSH18', 'PUSH19', 'PUSH20', 'PUSH21', 'PUSH22', 'PUSH23', 'PUSH24', 'PUSH25', 'PUSH26', 'PUSH27', 'PUSH28', 'PUSH29', 'PUSH30', 'PUSH31', 'PUSH32', 'DUP1', 'DUP2', 'DUP3', 'DUP4', 'DUP5', 'DUP6', 'DUP7', 'DUP8', 'DUP9', 'DUP10', 'DUP11', 'DUP12', 'DUP13', 'DUP14', 'DUP15', 'DUP16', 'SWAP1', 'SWAP2', 'SWAP3', 'SWAP4', 'SWAP5', 'SWAP6', 'SWAP7', 'SWAP8', 'SWAP9', 'SWAP10', 'SWAP11', 'SWAP12', 'SWAP13', 'SWAP14', 'SWAP15', 'SWAP16', 'LOGO', 'LOG1', 'LOG2', 'LOG3', 'LOG4', 'PUSH', 'DUP', 'SWAP']\n",
    "node_attrs = node_types + labels\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        self.Ngraph = 44\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        ngraph = self.Ngraph\n",
    "        vers = [f'{idx}.ver' for idx in range(ngraph)]\n",
    "        edgs = [f'{idx}.edg' for idx in range(ngraph)]\n",
    "        bugs = [f'{idx}.type' for idx in range(ngraph)]\n",
    "        return vers + edgs + bugs\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        ngraph = self.Ngraph\n",
    "        graphs = [f'{idx}.grap' for idx in range(ngraph)]\n",
    "        return graphs\n",
    "\n",
    "    def download(self):\n",
    "        #  download the source file to `self.raw_dir`.\n",
    "        pass\n",
    "        print(\"in download\")\n",
    "        # raise RuntimeError(\"in download\")\n",
    "\n",
    "    def process(self):\n",
    "        self.exist_processed_file_names = []\n",
    "        for i, j, files in os.walk(self.processed_dir):\n",
    "            self.exist_processed_file_names = files\n",
    "            break\n",
    "\n",
    "        for f in self.processed_file_names:\n",
    "          if f not in self.exist_processed_file_names:\n",
    "            print(f\"process new file {f}\")\n",
    "            out_path = os.path.join(self.processed_dir, f)\n",
    "            data = self._process_per_graph(f)\n",
    "            torch.save(data, out_path)\n",
    "    \n",
    "    def _process_per_graph(self, f):\n",
    "        idx = f[:-5]\n",
    "        verPath = os.path.join(self.raw_dir, idx+'.ver')\n",
    "        edgPath = os.path.join(self.raw_dir, idx+'.edg')\n",
    "        bugPath = os.path.join(self.raw_dir, idx+'.type')\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        x = []\n",
    "        for line in open(edgPath, \"r\"):\n",
    "            line = line.strip('\\n')\n",
    "            line = line.replace(' ', '').split(',')\n",
    "            link = [int(line[0]), int(line[1])]\n",
    "            edge_index.append(link)\n",
    "            if line[2] == 'exec':\n",
    "                attr = [0, int(line[3])]\n",
    "            else:\n",
    "                attr = [1, int(line[3])]\n",
    "            edge_attr.append(attr)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "        for line in open(verPath, \"r\"):\n",
    "            line = line.strip('\\n')\n",
    "            attrOneHot = [0 for i in range(len(node_attrs))]\n",
    "            line = line.replace(' ', '').replace('\\'','')\n",
    "            attr_begin = line.index('[')+1\n",
    "            nodeType = line[:attr_begin-1].split(',')[1]\n",
    "            attrList = line[attr_begin:-1].split(',')\n",
    "            if '' in attrList:\n",
    "                attrList.remove('')\n",
    "            attrList.append(nodeType)\n",
    "            for attr in attrList:\n",
    "                idx = node_attrs.index(attr)\n",
    "                attrOneHot[idx] = 1\n",
    "            x.append(attrOneHot)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "        for line in open(bugPath, \"r\"):\n",
    "          line = line.strip('\\n')\n",
    "          y = int(line)\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        return data\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, self.processed_file_names[idx]))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process new file 1.grap\n",
      "process new file 2.grap\n",
      "process new file 3.grap\n",
      "process new file 4.grap\n",
      "process new file 5.grap\n",
      "process new file 6.grap\n",
      "process new file 7.grap\n",
      "process new file 8.grap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process new file 9.grap\n",
      "process new file 10.grap\n",
      "process new file 11.grap\n",
      "process new file 12.grap\n",
      "process new file 13.grap\n",
      "process new file 14.grap\n",
      "process new file 15.grap\n",
      "process new file 16.grap\n",
      "process new file 17.grap\n",
      "process new file 18.grap\n",
      "process new file 19.grap\n",
      "process new file 20.grap\n",
      "process new file 21.grap\n",
      "process new file 22.grap\n",
      "process new file 23.grap\n",
      "process new file 24.grap\n",
      "process new file 25.grap\n",
      "process new file 26.grap\n",
      "process new file 27.grap\n",
      "process new file 28.grap\n",
      "process new file 29.grap\n",
      "process new file 30.grap\n",
      "process new file 31.grap\n",
      "process new file 32.grap\n",
      "process new file 33.grap\n",
      "process new file 34.grap\n",
      "process new file 35.grap\n",
      "process new file 36.grap\n",
      "process new file 37.grap\n",
      "process new file 38.grap\n",
      "process new file 39.grap\n",
      "process new file 40.grap\n",
      "process new file 41.grap\n",
      "process new file 42.grap\n",
      "process new file 43.grap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dst = MyOwnDataset(\"../data/smartbugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[105, 172], edge_index=[2, 162], edge_attr=[162, 2], y=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst.getitem(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "634ffc23e07d1ff39bbbc78f82419442f958d394482c657a5bd6f3ea84c523b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pye')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
